{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee9edd2",
   "metadata": {},
   "source": [
    "# 1. Data Preparation & Feature Engineering\n",
    "Refactored preprocessing utilities into allocation-ready feature engineering using NumPy and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d329e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Example synthetic schema for allocation tasks/resources\n",
    "df = pd.DataFrame({\n",
    "    'current_load':[10,35,60,80],\n",
    "    'distance':[0.3, 2.4, 1.1, 5.0],\n",
    "    'priority':[1,2,3,2]\n",
    "})\n",
    "\n",
    "df['normalised_load'] = (df['current_load']-df['current_load'].min())/(df['current_load'].max()-df['current_load'].min())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f0dc5",
   "metadata": {},
   "source": [
    "### Refactored utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9479230",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utility file\n",
    "utility functions like loading data and preprocessing images.\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\" Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns a Numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "\n",
    "    # Define how to the transform should happen\n",
    "    transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                         [0.229, 0.224, 0.225])])\n",
    "\n",
    "    # Open image and transform it\n",
    "    im = transform(Image.open(image_path))\n",
    "\n",
    "    # Return only the transformed image as a Tensor, since imshow will convert to Numpy array\n",
    "    return im\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "\n",
    "    new_image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    new_image = std * new_image + mean\n",
    "\n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    new_image = np.clip(new_image, 0, 1)\n",
    "\n",
    "    ax.imshow(new_image)\n",
    "\n",
    "    return ax\n",
    "\n",
    "#######################################################################################################################\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
